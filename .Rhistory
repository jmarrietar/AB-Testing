install.packages("KernSmooth")
require("KernSmooth")
require(KernSmooth)
load(KernSmooth)
library(KernSmooth)
library (KernSmooth)
install.packages("KernSmooth")
library(KernSmooth)
library(data.table)
library(KernSmooth)
require("XML")
library(KernSmooth)
install.packages("KernSmooth")
library(KernSmooth
library(data.table)
library(KernSmooth)
library(caret);
install.packages("caret")
library(kernlab)
install.packages("kernlab")
data(spam)
library(kernlab)
data(spam)
View(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
library(caret);
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
inTrain
View(inTrain)
spam[inTrain,]
inTrain
spam[-inTrain,]
View(inTrain)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
dim(training)
modelFit<-train(type -.,data=training,method="glm")
modelFit<-train(type ~.,data=training,method="glm")
modelFit
modelFit<-train(type ~.,data=training,method="glm")
set.seed(32343)
modelFit<-train(type ~.,data=training,method="glm")
install.packages('e1071', dependencies=TRUE)
modelFit<-train(type ~.,data=training,method="glm")
modelFit
modelfit$finalModel
modelFit$finalModel
modelFit$finalModel
modelFit$finalModel
predictions<-predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$Type)
confusionMatrix(predictions,testing$type)
folds<-createFolds(y=spam$type,k=10,list=T,returnTrain=T)
folds
sapply(folds,length)
folds[[1]][1:10]
set.seed(32323)
folds<-createResample(y=spam$type,times=10,list=T)
sapply(folds,length)
library(ISLR)
library(ggplot2)
library(caret)
library(ISLR)
library(ggplot2)
library(caret)
install.packages("ISLR")
data(Wage)
library(ISLR)
data(Wage)
data(Wage)
Wage
View(Wage)
summary(Wage)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dim(training)
dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq+geom_smooth(method='lm',formula=y~x)
qq<-qplot(age,wage,colour=jobclass,data=training)
qq+geom_smooth(method='lm',formula=y~x)
cutWage<-cut2(training$wage,g=3)
cut2
library(ISLR)
library(ggplot2)
library(caret)
cutWage<-cut2(training$wage,g=3)
install.packages("Hmisc")
library(Hmisc)
#MAKING FACTORSS!  CUT2 Function
cutWage<-cut2(training$wage,g=3)
#MAKING FACTORSS!  CUT2 Function
cutWage<-cut2(training$wage,g=3)
cutWage
table(cutWage)
p1<-qplot(cutWage,age,data=training,fill=cutWage,geom=c("boxplot"))
p1
t1<-table(cutWage,training$jobclass)
t1
qplot(wage,colour=education,data=training,geom="density")
library(caret);
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve<-training$capitalAve
trainCapAveS<-(trainCapAve-mean(trainCapAve))/sd(trainCapAve)
sd(trainCapAves)
sd(trainCapAveS)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
data(AlzheimerDisease)
library(caret)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
View(predictors)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
data(concrete)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(concrete)
plot(trainning$CompressiveStrength,pch=19)
plot(training$CompressiveStrength,pch=19)
plot(testing$CompressiveStrength,pch=19)
View(concrete)
plot(concrete$CompressiveStrength,pch=19)
View(concrete)
plot(concrete$FlyAsh,pch=19)
plot(concrete$FlyAsh,pch=19)
cutFlyAsh<-cut2(concrete$FlyAsh,g=4)
table(cutFlyAsh)
cutFlyAsh<-cut2(concrete$FlyAsh,g=4)
library(ISLR)
library(ggplot2)
library(caret)
library(Hmisc)
cutFlyAsh<-cut2(concrete$FlyAsh,g=4)
table(cutFlyAsh)
cutFlyAsh<-cut2(concrete$FlyAsh,g=3)
table(cutFlyAsh)
cutFlyAsh<-cut2(concrete$FlyAsh,g=3)
table(cutFlyAsh)
p1<-qplot(concrete$CompressiveStrength,data=concrete,fill=cutFlyAsh,geom=c("boxplot"))
p1
p1<-qplot(concrete$CompressiveStrength,data=concrete,fill=cutFlyAsh,geom=c("boxplot"))
p1
p1<-qplot(concrete$CompressiveStrength,data=concrete,color=cutFlyAsh,geom=c("boxplot"))
p1
p1<-qplot(concrete$CompressiveStrength,data=concrete,color=cutFlyAsh)
p1
plot(concrete$CompressiveStrength,color=cutFlyAsh)
p1<-qplot(concrete$CompressiveStrength,data=concrete)
p1
qplot(concrete$CompressiveStrength,data=concrete)
qplot(seq_along(concrete$CompressiveStrength), concrete$CompressiveStrength,data=concrete)
qplot(seq_along(concrete$CompressiveStrength), concrete$CompressiveStrength,data=concrete,colour=cutFlyAsh)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength,data=training,colour=cutFlyAsh)
qplot(seq_along(concrete$CompressiveStrength), concrete$CompressiveStrength,data=concrete,colour=cutFlyAsh)
plot(training$CompressiveStrength,pch=19)
qplot(seq_along(concrete$CompressiveStrength), concrete$CompressiveStrength,data=concrete,colour=cutFlyAsh)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength,data=training,colour=cutFlyAsh)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength,data=training)
p1
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength,data=training)
cutFlyAshT<-cut2(training$FlyAsh,g=3)
table(cutFlyAshT)
qplot(seq_along(training$CompressiveStrength), training$CompressiveStrength,data=training,colour=cutFlyAshT)
qplot(seq_along(concrete$CompressiveStrength), concrete$CompressiveStrength,data=concrete,colour=cutFlyAsh)
qplot(seq_along(concrete$CompressiveStrength), concrete$FlyAsh,data=concrete,colour=cutFlyAsh)
qplot(concrete$CompressiveStrength, concrete$FlyAsh,data=concrete,colour=cutFlyAsh)
plot(concrete$Superplasticizer,pch=19)
#Question 3
hist(concrete$Superplasticizer,pch=19)
hist(log(concrete$Superplasticizer+1),pch=19)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(adData)
View(training)
TPCA<-training[,c(65.75)]
TPCA<-training[,c(65,75)]
View(TPCA)
TPCA<-training[,c(65:75)]
View(TPCA)
TPCA<-training[,c(60:75)]
View(TPCA)
TPCA<-training[,c(50:73)]
View(TPCA)
TPCA<-training[,c(55:73)]
View(TPCA)
TPCA<-training[,c(58:73)]
View(TPCA)
TPCA<-training[,c(58:69)]
View(TPCA)
TPCA<-training[,c(58:70)]
View(TPCA)
TPCA<-training[,c(58:69)]
View(TPCA)
TPCA<-training[,c(58:69),row.names = FALS]
TPCA<-training[,c(58:69),row.names = FALSE]
TPCA<-training[,c(58:69)]
TPCA$row.names<-null
TPCA$row.names<-NULL
View(TPCA)
TPCA$row.names<-NULL
View(TPCA)
preProc<-preProcess(TPCA,method="pca",pcaComp=2)
preProc<-preProcess(TPCA,method="pca",pcaComp=2)
trainPC<-predict(preProc,TPCA)
modelFit<-train(training$type~.,method="glm",data=TrainPC)
trainPC<-predict(preProc,TPCA)
modelFit<-train(training$type~.,method="glm",data=trainPC)
preProc
trainPC
preProc
preProc
trainPC
summary(trainPC)
preProc<-preProcess(TPCA,method="pca",thresh=0.8)
preProc$rotation
preProc<-preProcess(TPCA,method="pca",thresh=0.8)
preProc$rotation
#Question 4
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
TPCA<-training[,c(58:69)]
preProc<-preProcess(TPCA,method="pca",thresh=0.8)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
trainingP<-training[,c(1,58:69)]
View(trainingP)
testing
View(testing)
testing
View(testing)
testing$Type,
testing$Type
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
testing$Type
testing$type
training$type
preProc
trainPC
trainPC<-predict(preProc,TPCA)
trainPC
modelFit<-train(training$type~.,method="glm",data=trainPC)
View(trainPC)
View(training)
modelFit<-train(training$diagnosis~.,method="glm",data=trainPC)
testPC<-predict(preProc,testing[,-58])
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
testPC<-predict(preProc,testing[,-58])
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingP<-training[,c(1,58:69)]
View(trainingP)
trainPC
preProc<-preProcess(trainingP,method="pca",thresh=0.8)
preProc<-preProcess(trainingP[,-1],method="pca",thresh=0.8)
trainPC<-predict(preProc,trainingP)
trainPC<-predict(preProc,trainingP[,-1])
preProc<-preProcess(trainingP[,-1],method="pca",thresh=0.8)
trainPC<-predict(preProc,trainingP[,-1])
modelFit<-train(training$diagnosis~.,method="glm",data=trainPC)
View(testing)
testPC<-predict(preProc,testing[,-1])
trainingP<-training[,c(1,58:69)]
testingP<-testing[,c(1,58:69)]
testPC<-predict(preProc,testingP[,-1])
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
trainPC
modelFit1<-train(training$diagnosis~.,method="glm",data=training[-1])
modelFit1
confusionMatrix(testing$diagnosis,predict(modelFit1,testingP[,-1]))
confusionMatrix(testingP$diagnosis,predict(modelFit,testPC))
#one using PCA with principal components explaining 80% of the variance in the predictors.
preProc<-preProcess(trainingP[,-1],method="pca",thresh=0.8)
trainPC<-predict(preProc,trainingP[,-1])
modelFit<-train(training$diagnosis~.,method="glm",data=trainPC)
testPC<-predict(preProc,testingP[,-1])
confusionMatrix(testingP$diagnosis,predict(modelFit,testPC))
modelFit1<-train(trainingP$diagnosis~.,method="glm",data=trainingP[-1])
confusionMatrix(testingP$diagnosis,predict(modelFit1,testingP[,-1]))
Mtarix1<-confusionMatrix(testingP$diagnosis,predict(modelFit1,testingP[,-1]))
Matrix2<-confusionMatrix(testingP$diagnosis,predict(modelFit,testPC))
preProc
trainPC
preProc
Mtarix1
Matrix2
clear
Abandoned_Data<-read.csv("Abandoned_Data_Seed.csv",header=TRUE,na.strings = "")
Reservation_Data<-read.csv("Reservation_Data_Seed.csv",header=T,na.strings = "")
###################################################################
setwd("C:/Users/Alfonso/Desktop/JOM/AB-Testing")
Abandoned_Data<-read.csv("Abandoned_Data_Seed.csv",header=TRUE,na.strings = "")
Reservation_Data<-read.csv("Reservation_Data_Seed.csv",header=T,na.strings = "")
Email_matches<-Abandoned_Data$Email %in% Reservation_Data$Email
table(match(Abandoned_Data$Email, Reservation_Data$Email, nomatch = 0))
match(Abandoned_Data$Email, Reservation_Data$Email, nomatch = 0)
table(match(Abandoned_Data$Email, Reservation_Data$Email, nomatch = 0,incomparables = NULL))
table(match(Abandoned_Data$Email, Reservation_Data$Email, nomatch = 0,incomparables = NA))
match(Abandoned_Data$Email, Reservation_Data$Email, nomatch = 0
)
Abandoned_Data$Email[,8161]
Abandoned_Data$Email[1]
Abandoned_Data$Email[8241]
Abandoned_Data$Email[8425]
Abandoned_Data$Email[8426]
table(match(Abandoned_Data$Email, Reservation_Data$Email, nomatch = 0))
table(match(Abandoned_Data$Contact_Phone, Reservation_Data$Contact_Phone, nomatch = 0))
sum((match(Abandoned_Data$Contact_Phone, Reservation_Data$Contact_Phone, nomatch = 0))>0)
sum((match(Abandoned_Data$Contact_Phone, Reservation_Data$Contact_Phone, nomatch = 0))>0)
sum((match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0))>0)
table(match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0))
(match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0)
)
Abandoned_Data$Incoming_Phone[7393]
sum((match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0)) >0 && !=5 )
sum((match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0))!=7393 )
sum((match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0))>0 )
table(match(Abandoned_Data$Incoming_Phone, Reservation_Data$Incoming_Phone, nomatch = 0))
Abandoned_Data_Clean<-Abandoned_Data[!duplicated(Abandoned_Data$Incoming_Phone),]
Reservation_Data_Clean<-Reservation_Data[!duplicated(Reservation_Data$Incoming_Phone),]
Incoming_Phone_matches<-Abandoned_Data_Clean$Incoming_Phone %in% Reservation_Data_Clean$Incoming_Phone
Incoming_Phone_matches
Abandoned_Data_Clean<-Abandoned_Data[!duplicated(Abandoned_Data$Incoming_Phone),]
Reservation_Data_Clean<-Reservation_Data[!duplicated(Reservation_Data$Incoming_Phone),]
View(Reservation_Data)
#Remove rows with NA values in Incoming Phones column!
AData<-completeFun(DF, "Incoming_Phone")
RData<-completeFun(DF, "Incoming_Phone")
AData<-subset(DF, !is.na("Incoming_Phone"))
RData<-subset(DF, !is.na("Incoming_Phone"))
AData<-subset(Abandoned_Data, !is.na("Incoming_Phone"))
RData<-subset(Reservation_Data, !is.na("Incoming_Phone"))
RData<-subset(Reservation_Data, !is.na(Incoming_Phone))
AData<-subset(Abandoned_Data, !is.na(Incoming_Phone))
View(AData)
View(RData)
Incoming_Phone_matches<-AData$Incoming_Phone %in% RData$Incoming_Phone
sum(Incoming_Phone_matches>0)
AData_Clean<-AData[!duplicated(AData$Incoming_Phone),]
RData_Clean<-RData[!duplicated(RData$Incoming_Phone),]
unique(AData)
AData<-subset(Abandoned_Data, !is.na(Incoming_Phone))
RData<-subset(Reservation_Data, !is.na(Incoming_Phone))
Incoming_Phone_matches<-AData$Incoming_Phone %in% RData$Incoming_Phone
sum(Incoming_Phone_matches>0)
sum(Incoming_Phone_matches>0)
b_obs<-conversion_data$b
setwd("C:/Users/JosePortatil/Dropbox/Data Science/Team_Leada/AB_Testing")
conversion_data<-read.csv('landing_page_data.csv',header=TRUE)
#We want to determine if the convertion rate
#for landing page B is higher than the rate for A
sum(conversion_data$b)
sum(conversion_data$a,na.rm=T)
#Z-test and T-Test
#p1 p2 proportion of 1s in the two columns respectively.
a_obs<-na.omit(conversion_data$a)
b_obs<-conversion_data$b
a_obs<
)
a_obs
b_obs
